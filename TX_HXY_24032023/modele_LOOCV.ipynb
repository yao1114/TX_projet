{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/04/2023  LOOCV\n",
    "\n",
    "Voici des explications pour chaque section de code:\n",
    "\n",
    "1. Function read_and_split_data\n",
    "- lire le fichier de données\n",
    "- diviser l'ensemble de données en ensembles train et de test par LOOCV\n",
    "- prétraiter la variable cible pour Convertir multi-classe en bi-classe(remplaçant 1 et 3 par 2, et 2 par 1).\n",
    "\n",
    "2. Funtion evaluate_model_performance\n",
    "- évaluer les performances du modèle sur l'ensemble de test, \n",
    "- compris la précision (accuracy), la matrice de confusion (confusion matrix), l'AUC et la valeur F1.\n",
    "\n",
    "3. Pipeline:\n",
    "   Définissez l'objet Pipeline, qui contient le classificateur (DecisionTreeClassifier, Random Forest, SVC, Logistic Regression).\n",
    "\n",
    "4. Param_grid: \n",
    "   Définissez l'espace de paramètres hyperparamétriques param_grid.\n",
    "\n",
    "5. GridSearchCV:\n",
    "   Utilisez l'objet GridSearchCV pour rechercher la meilleure combinaison de paramètres hyperparamétriques, en utilisant une validation croisée LOOCV et une recherche en grille pour évaluer la précision.\n",
    "\n",
    "## Les résultats de l'exécution des quatre modèles sont les suivants :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "83430 fits failed out of a total of 185400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9270 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.64401294        nan 0.55987055 0.66278317\n",
      " 0.5605178  0.5605178  0.55987055 0.55987055        nan        nan\n",
      "        nan        nan        nan 0.64854369 0.5605178         nan\n",
      " 0.55987055 0.55987055        nan        nan 0.68220065        nan\n",
      " 0.55987055 0.65436893 0.5605178  0.5605178  0.55987055 0.55987055\n",
      "        nan        nan        nan        nan        nan 0.64854369\n",
      " 0.5605178         nan 0.55987055 0.55987055        nan        nan\n",
      " 0.69902913        nan 0.55987055 0.65113269 0.5605178  0.5605178\n",
      " 0.55987055 0.55987055        nan        nan        nan        nan\n",
      "        nan 0.64854369 0.5605178         nan 0.55987055 0.55987055\n",
      "        nan        nan 0.70226537        nan 0.55987055 0.65177994\n",
      " 0.5605178  0.5605178  0.55987055 0.55987055        nan        nan\n",
      "        nan        nan        nan 0.64854369 0.5605178         nan\n",
      " 0.55987055 0.55987055        nan        nan 0.70226537        nan\n",
      " 0.55987055 0.65825243 0.5605178  0.5605178  0.55987055 0.55987055\n",
      "        nan        nan        nan        nan        nan 0.64854369\n",
      " 0.5605178         nan 0.55987055 0.55987055        nan        nan\n",
      " 0.70032362        nan 0.55987055 0.64983819 0.5605178  0.5605178\n",
      " 0.55987055 0.55987055        nan        nan        nan        nan\n",
      "        nan 0.64854369 0.5605178         nan 0.55987055 0.55987055]\n",
      "  warnings.warn(\n",
      "c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Accuracy:  0.6764705882352942\n",
      "Accuracy for class Stress: 0.573\n",
      "Accuracy for class Relax: 0.757\n",
      "\n",
      "Confusion Matrix: \n",
      " [[0.57303371 0.42696629]\n",
      " [0.24347826 0.75652174]]\n",
      "\n",
      "AUC:  0.6647777234978016\n",
      "\n",
      "F1-score for class Stress: 0.729\n",
      "F1-score for class Relax: 0.861\n",
      "F1-score: 0.6071428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huxua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "# Define a function to read and split the dataset\n",
    "def read_and_split_data_(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Copy target variable\n",
    "    y = data['session'].copy()\n",
    "    # Replace 1 and 3 with 2, and 2 with 1 in y\n",
    "    y.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "    # Split the dataset into a training set and a test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], y, test_size=test_size, \n",
    "                                                        stratify=y, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def read_and_split_data(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    y_binary = data['session'].copy()\n",
    "    y_binary.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "\n",
    "    # Divided with same IDs split together\n",
    "    unique_ids = data['ID'].unique()\n",
    "    test_ids = set(pd.Series(unique_ids).sample(frac=0.2, random_state=40))\n",
    "    train_data = data[data['ID'].apply(lambda x: x not in test_ids)]\n",
    "    test_data = data[data['ID'].apply(lambda x: x in test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-1], y_binary[train_data.index]\n",
    "    X_test, y_test = test_data.iloc[:, :-1], y_binary[test_data.index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Define a function to evaluate model performance\n",
    "def evaluate_model_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', labels=[1, 2])\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Accuracy for class Stress: {:.3f}'.format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "    print('Accuracy for class Relax: {:.3f}'.format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "    print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, y_pred, normalize='true'))\n",
    "    print('\\nAUC: ', roc_auc_score(y_test, y_pred))\n",
    "    print('\\nF1-score for class Stress: {:.3f}'.format(f1_score(y_test[y_test==1], y_pred[y_test==1], average='weighted')))\n",
    "    print('F1-score for class Relax: {:.3f}'.format(f1_score(y_test[y_test==2], y_pred[y_test==2], average='weighted')))\n",
    "    print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Define a pipeline to link data preprocessing and model training and evaluation\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression(random_state=40))\n",
    "])\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=LeaveOneOut(), # LeaveOneOut\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Read and split the dataset\n",
    "X_train, X_test, y_train, y_test = read_and_split_data('HRV_ECG_step60.csv')\n",
    "\n",
    "# Fit GridSearchCV object on the training dataset\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "\n",
    "# Fit LogisticRegression object with best hyperparameters on the training dataset\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluate_model_performance(best_model, X_test, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "Accuracy:  0.6372549019607843\n",
      "Accuracy for class Stress: 0.629\n",
      "Accuracy for class Relax: 0.643\n",
      "\n",
      "Confusion Matrix: \n",
      " [[0.62921348 0.37078652]\n",
      " [0.35652174 0.64347826]]\n",
      "\n",
      "AUC:  0.6363458720078162\n",
      "\n",
      "F1-score for class Stress: 0.772\n",
      "F1-score for class Relax: 0.783\n",
      "F1-score: 0.6021505376344086\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "# Define a function to read and split the dataset\n",
    "def read_and_split_data(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    y_binary = data['session'].copy()\n",
    "    y_binary.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "\n",
    "    # Divided with same IDs split together\n",
    "    unique_ids = data['ID'].unique()\n",
    "    test_ids = set(pd.Series(unique_ids).sample(frac=0.2, random_state=40))\n",
    "    train_data = data[data['ID'].apply(lambda x: x not in test_ids)]\n",
    "    test_data = data[data['ID'].apply(lambda x: x in test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-1], y_binary[train_data.index]\n",
    "    X_test, y_test = test_data.iloc[:, :-1], y_binary[test_data.index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Define a function to evaluate model performance\n",
    "def evaluate_model_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', labels=[1, 2])\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Accuracy for class Stress: {:.3f}'.format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "    print('Accuracy for class Relax: {:.3f}'.format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "    print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, y_pred, normalize='true'))\n",
    "    print('\\nAUC: ', roc_auc_score(y_test, y_pred))\n",
    "    print('\\nF1-score for class Stress: {:.3f}'.format(f1_score(y_test[y_test==1], y_pred[y_test==1], average='weighted')))\n",
    "    print('F1-score for class Relax: {:.3f}'.format(f1_score(y_test[y_test==2], y_pred[y_test==2], average='weighted')))\n",
    "    print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Define a pipeline to link data preprocessing and model training and evaluation\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier(random_state=40))\n",
    "])\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [2, 5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=LeaveOneOut(), # LeaveOneOut\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Read and split the dataset\n",
    "X_train, X_test, y_train, y_test = read_and_split_data('HRV_ECG_step60.csv')\n",
    "\n",
    "# Fit GridSearchCV object on the training dataset\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "\n",
    "# Fit DecisionTreeClassifier object with best hyperparameters on the training dataset\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluate_model_performance(best_model, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__kernel': 'rbf', 'classifier__gamma': 0.1, 'classifier__C': 10.0}\n",
      "Accuracy:  0.5686274509803921\n",
      "Accuracy for class Stress: 0.534\n",
      "Accuracy for class Relax: 0.596\n",
      "\n",
      "Confusion Matrix: \n",
      " [[0.53370787 0.46629213]\n",
      " [0.40434783 0.59565217]]\n",
      "\n",
      "AUC:  0.5646800195407915\n",
      "\n",
      "F1-score for class Stress: 0.696\n",
      "F1-score for class Relax: 0.747\n",
      "F1-score: 0.5191256830601093\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define a function to read and split the dataset\n",
    "def read_and_split_data_(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Copy target variable\n",
    "    y = data['session'].copy()\n",
    "    # Replace 1 and 3 with 2, and 2 with 1 in y\n",
    "    y.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "    # Split the dataset into a training set and a test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], y, test_size=test_size, \n",
    "                                                        stratify=y, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def read_and_split_data(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    y_binary = data['session'].copy()\n",
    "    y_binary.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "\n",
    "    # Divided with same IDs split together\n",
    "    unique_ids = data['ID'].unique()\n",
    "    test_ids = set(pd.Series(unique_ids).sample(frac=0.2, random_state=40))\n",
    "    train_data = data[data['ID'].apply(lambda x: x not in test_ids)]\n",
    "    test_data = data[data['ID'].apply(lambda x: x in test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-1], y_binary[train_data.index]\n",
    "    X_test, y_test = test_data.iloc[:, :-1], y_binary[test_data.index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Define a function to evaluate model performance\n",
    "def evaluate_model_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', labels=[1, 2])\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Accuracy for class Stress: {:.3f}'.format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "    print('Accuracy for class Relax: {:.3f}'.format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "    print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, y_pred, normalize='true'))\n",
    "    print('\\nAUC: ', roc_auc_score(y_test, y_pred))\n",
    "    print('\\nF1-score for class Stress: {:.3f}'.format(f1_score(y_test[y_test==1], y_pred[y_test==1], average='weighted')))\n",
    "    print('F1-score for class Relax: {:.3f}'.format(f1_score(y_test[y_test==2], y_pred[y_test==2], average='weighted')))\n",
    "    print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Define a pipeline to link data preprocessing and model training and evaluation\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(random_state=40))\n",
    "])\n",
    "\n",
    "# Define hyperparameter distributions for random search\n",
    "param_distributions = {\n",
    "    'classifier__C': np.logspace(-3, 3, 7),\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7)),\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    cv=LeaveOneOut(), # LeaveOneOut\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    n_iter=50, # number of random search iterations\n",
    "    random_state=40,\n",
    ")\n",
    "\n",
    "# Read and split the dataset\n",
    "X_train, X_test, y_train, y_test = read_and_split_data('HRV_ECG_step60.csv')\n",
    "\n",
    "# Fit RandomizedSearchCV object on the training dataset\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('Best parameters:', random_search.best_params_)\n",
    "\n",
    "# Fit SVM object with best hyperparameters on the training dataset\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluate_model_performance(best_model, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500}\n",
      "Accuracy:  0.6348039215686274\n",
      "Accuracy for class Stress: 0.629\n",
      "Accuracy for class Relax: 0.639\n",
      "\n",
      "Confusion Matrix: \n",
      " [[0.62921348 0.37078652]\n",
      " [0.36086957 0.63913043]]\n",
      "\n",
      "AUC:  0.6341719589643381\n",
      "\n",
      "F1-score for class Stress: 0.772\n",
      "F1-score for class Relax: 0.780\n",
      "F1-score: 0.6005361930294906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "# Define a function to read and split the dataset\n",
    "def read_and_split_data_(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Copy target variable\n",
    "    y = data['session'].copy()\n",
    "    # Replace 1 and 3 with 2, and 2 with 1 in y\n",
    "    y.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "    # Split the dataset into a training set and a test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], y, test_size=test_size, \n",
    "                                                        stratify=y, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def read_and_split_data(file_path, test_size=0.2, random_state=40):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    y_binary = data['session'].copy()\n",
    "    y_binary.replace({1: 2, 2: 1, 3: 2}, inplace=True)\n",
    "\n",
    "    # Divided with same IDs split together\n",
    "    unique_ids = data['ID'].unique()\n",
    "    test_ids = set(pd.Series(unique_ids).sample(frac=0.2, random_state=40))\n",
    "    train_data = data[data['ID'].apply(lambda x: x not in test_ids)]\n",
    "    test_data = data[data['ID'].apply(lambda x: x in test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-1], y_binary[train_data.index]\n",
    "    X_test, y_test = test_data.iloc[:, :-1], y_binary[test_data.index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Define a function to evaluate model performance\n",
    "def evaluate_model_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', labels=[1, 2])\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Accuracy for class Stress: {:.3f}'.format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "    print('Accuracy for class Relax: {:.3f}'.format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "    print('\\nConfusion Matrix: \\n', confusion_matrix(y_test, y_pred, normalize='true'))\n",
    "    print('\\nAUC: ', roc_auc_score(y_test, y_pred))\n",
    "    print('\\nF1-score for class Stress: {:.3f}'.format(f1_score(y_test[y_test==1], y_pred[y_test==1], average='weighted')))\n",
    "    print('F1-score for class Relax: {:.3f}'.format(f1_score(y_test[y_test==2], y_pred[y_test==2], average='weighted')))\n",
    "    print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Define a pipeline to link data preprocessing and model training and evaluation\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=40))\n",
    "])\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 300, 500],\n",
    "    'classifier__max_depth': [2, 5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=LeaveOneOut(), # LeaveOneOut\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Read and split the dataset\n",
    "X_train, X_test, y_train, y_test = read_and_split_data('HRV_ECG_step60.csv')\n",
    "\n",
    "# Fit GridSearchCV object on the training dataset\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "\n",
    "# Fit RandomForestClassifier object with best hyperparameters on the training dataset\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluate_model_performance(best_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
